---
title: "p8105_hw3_smy2122"
author: "Sarah Younes"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

As always, I will begin by loading all the packages I will need for this homework assignment: tidyverse, ggridges, and p8105.datasets.

```{r load packages, message = FALSE}
library(tidyverse)
library(ggridges)
library(p8105.datasets)
```

# Problem 1

First, I will load the Instacart data set.

```{r load instacart dataset}
data("instacart")

instacart_df =
  instacart |>
  as_tibble()
```

The Instacart data set contains `r ncol(instacart_df)` variables and `r nrow(instacart_df)` observations. There are `r instacart_df |> select(product_id) |> distinct() |> count()` products found in `r instacart_df |> select(user_id, order_id) |> distinct() |> count()` orders from `r instacart_df |> select(user_id) |> distinct() |> count()` distinct users.

Furthermore, there are `r length(unique(instacart_df$aisle_id))` aisles. The aisle most frequently ordered from is aisle `r names(which.max(table(instacart_df$aisle_id)))`, otherwise known as `r names(which.max(table(instacart_df$aisle)))`. According to the code below, the fresh vegetables and fresh fruits aisles had the most products.

```{r instacart aisles}
instacart_df |>
  count(aisle) |>
  arrange(desc(n))
```

Below is a plot that shows the number of items ordered in each aisle for aisles with more than 10,000 items ordered.

```{r instacart plot}
instacart_df |>
  count(aisle) |>
  filter(n > 10000) |>
  mutate(aisle = fct_reorder(aisle, n)) |>
  ggplot(aes(x = aisle, y = n, color = aisle)) +
  geom_point() +
  labs(title = "Number of items ordered in each aisle") +
  labs(caption = "Among aisles with more than 10,000 items ordered")
```

Now, I will make a table showing the top 3 most popular items in 3 aisles (baking ingredients, dog food care, and packaged vegetables fruits) and the number of times each item was ordered.

```{r instacart table}
instacart_df |>
  filter(
    aisle == c("baking ingredients", "dog food care", "packaged vegetables fruits")
  ) |>
  select(aisle, product_name, order_id) |>
  group_by(aisle) |> 
  count(product_name) |> 
  mutate(rank = min_rank(desc(n))) |> 
  filter(rank < 4) |> 
  arrange(desc(n)) |>
  knitr::kable()
```

Now, I will make a table showing the mean hour of the day at which two items were ordered on each day of the week.

```{r day of week table, message = FALSE}
instacart_df |>
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) |>
  group_by(product_name, order_dow) |>
  summarize(mean_hour = mean(order_hour_of_day)) |>
  pivot_wider(
    names_from = order_dow, 
    values_from = mean_hour) |>
  knitr::kable()
```

# Problem 2

First, I will load the BRFSS dataset.

```{r loading brffs dataset}
library(p8105.datasets)
data("brfss_smart2010")
```

Now, I will create a data frame for the data set and do some data cleaning: formatting the data to use appropriate variable names, filtering the data set to focus on the "Overall Health" topic, and organizing responses as a factor taking levels ordered from "Poor" to "Excellent."

```{r brffs data cleaning}
brffs_df =
  p8105.datasets::brfss_smart2010 |>
  janitor::clean_names() |>
  separate(locationdesc, into = c("state", "county"), sep = 5) |>
  select(everything(), -state) |>
  rename(state = locationabbr) |>
  filter(
    topic == "Overall Health",
    response %in% c("Poor", "Fair", "Good", "Very good", "Excellent")) |>
  mutate(response = fct_relevel(response, c("Poor", "Fair", "Good", "Very good", "Excellent"))) |>
  select(year, state, county, topic, response, data_value)
```

The tables below show the states that were observed at 7 or more locations in 2002 and 2010.

```{r states observed, message = FALSE}
brffs_df |>
  select(year, state, county) |>
  filter(year == 2002) |>
  distinct() |>
  group_by(state, year) |>
  summarize(n = n()) |>
  filter(n >= 7) |>
  arrange(year, desc(n)) |>
  knitr::kable()

brffs_df |>
  select(year, state, county) |>
  filter(year == 2010) |>
  distinct() |>
  group_by(state, year) |>
  summarize(n = n()) |>
  filter(n >= 7) |>
  arrange(year, desc(n)) |>
  knitr::kable()
```

Below is a spaghetti plot showing the average value over time for each state from 2002 to 2010. Overall, the plot shows a slight decrease in mean value over time across most states despite immense variation across state and year.

```{r spaghetti plot, message = FALSE, warning = FALSE}
brffs_df |>
  filter(response == "Excellent") |>
  group_by(year, state) |>
  summarize(mean_data_value = mean(data_value)) |>
  ggplot(aes(x = year, y = mean_data_value, group = state, color = state)) +
  geom_line() +
  labs(
    x = "Year",
    y = "Mean value",
    color = "State",
    title = "The average data value over time for each state from 2002 to 2010")
```

Below is a two-panel plot showing the distribution of data value for responses among locations in New York State in 2006 and 2010. The plot shows that data values were highest for "Very good" and "Good" responses in both 2006 and 2010.

```{r two-panel plot, warning = FALSE}
brffs_df |>
  filter(
    year == c(2006, 2010),
    state == "NY") |>
  ggplot(aes(x = response, y = data_value)) +
  geom_boxplot() +
  facet_grid(. ~ year) +
  labs(
    x = "Response",
    y = "Data value",
    color = "Location",
    title = "Distribution of data values for responses among locations in New York State in 2006 and 2010"
  )
```

# Problem 3

First, I will import, clean, and tidy the two data sets. As part of data cleaning for the demographics data set, I will remove the unnecessary rows, set missing values, clean variable names, exclude participants under age 21, drop those with missing demographic data, encode sex and education as factors, and re-level education. Data cleaning for the accelerometer data set only needs cleaning variable names, as there are no unnecessary rows and no missing values.

```{r load and clean data sets, message = FALSE}
demographic_df =
  read_csv(
    "./data/nhanes_covar.csv",
    skip = 4,
    na = "NA") |>
  janitor::clean_names() |>
  filter(age >= 21) |>
  drop_na() |>
  mutate(
    sex =
      case_match(
        sex,
        1 ~ "male",
        2 ~ "female"),
        sex = as.factor(sex)
  ) |>
  mutate(
    education =
      case_match(
        education,
        1 ~ "less than high school",
        2 ~ "high school equivalent",
        3 ~ "more than high school"),
    education = as.factor(education)
  ) |>
  mutate(education = fct_relevel(education, c("less than high school", "high school equivalent", "more than high school")))

accelerometer_df =
  read_csv("./data/nhanes_accel.csv") |>
  janitor::clean_names()
```

Now, I will merge the two data sets using an inner join to only show participants in both data sets.

```{r merge, message = FALSE}
merged_df =
  inner_join(demographic_df, accelerometer_df)
```

Below is a table of the number of men and women in each education category.

```{r table}
merged_df |>
  count(sex, education) |>
  pivot_wider(
    names_from = "education",
    values_from = n
  ) |>
  knitr::kable()
```

Below is a box plot of the age distributions for men and women in each education category. The box plot shows that

```{r age distribution plot}
merged_df |>
  ggplot(aes(x = sex, y = age)) +
  geom_boxplot() +
  facet_grid(. ~ education) +
  labs(
    x = "Sex",
    y = "Age",
    title = "Age distribution among men and women in each education category"
  )
```

Below is a three-panel plot of total activity over the day for men and women of each education level. The plot shows that total physical activity decreases most sharply for men and women with less than a high school education and least sharply for men and women with more than a high school education. Among men and women with a high school education or equivalent, total physical activity sharply dropped between ages 60-63 but then sharply increased around ages 70-34, and a similar (although less strong) trend occurred for men but not women with more than a high school education. By age 80, females with more than a high school education had the highest total physical activity.

```{r total activity plot, message = FALSE, warning = FALSE}
merged_df |>
  group_by(seqn) |>
  pivot_longer(
    min1:min1440,
    names_to = "minute",
    values_to = "activity"
  ) |>
  mutate(total_activity = sum(activity)) |>
  select(seqn, sex, age, bmi, education, total_activity) |>
  ggplot(aes(x = age, y = total_activity)) +
  geom_point() +
  geom_smooth() +
  facet_grid(sex ~ education) +
  labs(
    x = "Age",
    y = "Total physical activity over the day (measured by MIMS)",
    title = "Comparison of the total physical activity over the day for men and women of each education level"
  )
```

Below is a three-panel plot that shows the 24-hour activity time courses for each education level. The plot shows that, for those with less than a high school education or with a high school education or equivalent, physical activity is highest on average in the early afternoon before noon, whereas for those with more than a high school education, physical activity peaks twice: right before noon and in the evening. (This trend may reflect the possibility that men and women with more than a high school education may be more likely to work traditional 9am to 5pm corporate-style jobs.) Physical activity for women of all education levels seems highest before noon whereas physical activity for men of all education levels seems highest in the evening.

```{r three-panel plot, message = FALSE, warning = FALSE}
merged_df |>
  pivot_longer(
    min1:min1440,
    names_to = "minute",
    names_prefix = "min",
    values_to = "activity"
  ) |>
  mutate(minute = as.numeric(minute)) |>
  ggplot(aes(x = minute, y = activity, color = sex)) +
  geom_line() +
  geom_smooth(aes(group = sex)) +
  facet_grid(. ~ education) +
  labs(
    x = "Minute",
    y = "Physical activity (measured by MIMS)",
    color = "Sex",
    title = "24-hour physical activity for each education level"
  )
```