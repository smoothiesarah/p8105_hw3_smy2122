---
title: "p8105_hw3_smy2122"
author: "Sarah Younes"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

First, I will load all the packages I will need for this homework assignment: tidyverse.

```{r load packages, message = FALSE}
library(tidyverse)
library(p8105.datasets)
```

# Problem 1

First, I will load the Instacart data set.

```{r load instacart dataset}
data("instacart")

instacart_df =
  instacart |>
  as_tibble()
```

The Instacart data set contains `r ncol(instacart_df)` variables and `r nrow(instacart_df)` observations. There are `r instacart_df |> select(product_id) |> distinct() |> count()` products found in `r instacart_df |> select(user_id, order_id) |> distinct() |> count()` orders from `r instacart_df |> select(user_id) |> distinct() |> count()` distinct users.

Furthermore, there are `r length(unique(instacart_df$aisle_id))` aisles. The aisle most frequently ordered from is aisle `r names(which.max(table(instacart_df$aisle_id)))`, otherwise known as `r names(which.max(table(instacart_df$aisle)))`. According to the code below, the fresh vegetables and fresh fruits aisles had the most products.

```{r instacart aisles}
instacart_df |>
  count(aisle) |>
  arrange(desc(n))
```

Below is a plot that shows the number of items ordered in each aisle for aisles with more than 10,000 items ordered.

```{r instacart plot}
instacart_df |>
  count(aisle) |>
  filter(n > 10000) |>
  mutate(aisle = fct_reorder(aisle, n)) |>
  ggplot(aes(x = aisle, y = n, color = aisle)) +
  geom_point() +
  labs(title = "Number of items ordered in each aisle") +
  labs(caption = "Among aisles with more than 10,000 items ordered")
```

Now, I will make a table showing the top 3 most popular items in 3 aisles (baking ingredients, dog food care, and packaged vegetables fruits) and the number of times each item was ordered.

```{r instacart table}
instacart_df |>
  filter(
    aisle == c("baking ingredients", "dog food care", "packaged vegetables fruits")
  ) |>
  select(aisle, product_name, order_id) |>
  group_by(aisle) |> 
  count(product_name) |> 
  mutate(rank = min_rank(desc(n))) |> 
  filter(rank < 4) |> 
  arrange(desc(n)) |>
  knitr::kable()
```

Now, I will make a table showing the mean hour of the day at which two items were ordered on each day of the week.

```{r}
instacart_df |>
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) |>
  group_by(product_name, order_dow) |>
  summarize(mean_hour = mean(order_hour_of_day)) |>
  pivot_wider(
    names_from = order_dow, 
    values_from = mean_hour) |>
  knitr::kable()
```

# Problem 2

First, I will load the BRFSS dataset.

```{r loading brffs dataset}
library(p8105.datasets)
data("brfss_smart2010")
```

Now, I will create a data frame for the data set and do some data cleaning: formatting the data to use appropriate variable names, filtering the data set to focus on the "Overall Health" topic, and organizing responses as a factor taking levels ordered from "Poor" to "Excellent."

```{r brffs data cleaning}
brffs_df =
  p8105.datasets::brfss_smart2010 |>
  janitor::clean_names() |>
  separate(locationdesc, into = c("state", "county"), sep = 5) |>
  select(everything(), -state) |>
  rename(state = locationabbr) |>
  filter(
    topic == "Overall Health",
    response %in% c("Poor", "Fair", "Good", "Very good", "Excellent")) |>
  mutate(response = fct_relevel(response, c("Poor", "Fair", "Good", "Very good", "Excellent"))) |>
  select(year, state, county, topic, response, data_value)
```

Now, I will identify the states that were observed at 7 or more locations in 2002 and 2010.

```{r states observed}
brffs_df |>
  select(year, state, county) |>
  filter(year == 2002) |>
  distinct() |>
  group_by(state, year) |>
  summarize(n = n()) |>
  filter(n >= 7) |>
  arrange(year, desc(n)) |>
  knitr::kable()

brffs_df |>
  select(year, state, county) |>
  filter(year == 2010) |>
  distinct() |>
  group_by(state, year) |>
  summarize(n = n()) |>
  filter(n >= 7) |>
  arrange(year, desc(n)) |>
  knitr::kable()
```

Now, I will make a spaghetti plot showing the average value over time for each state from 2002 to 2010.

```{r spaghetti plot, message=FALSE, warning=FALSE}
brffs_df |>
  filter(response == "Excellent") |>
  group_by(year, state) |>
  summarize(mean_data_value = mean(data_value)) |>
  ggplot(aes(x = year, y = mean_data_value, group = state, color = state)) +
  geom_line() +
  labs(
    x = "Year",
    y = "Mean value",
    color = "State",
    title = "The average data value over time for each state from 2002 to 2010")
```

Below is a two-panel plot showing the distribution of data value for responses among locations in New York State in 2006 and 2010.

```{r two-panel plot}
brffs_df |>
  filter(
    year == c(2006, 2010),
    state == "NY") |>
  ggplot(aes(x = response, y = data_value, color = county)) +
  geom_boxplot() +
  facet_grid(. ~ year) +
  labs(
    x = "Response",
    y = "Data value",
    color = "Location",
    title = "Distribution of data values for responses among locations in New York State in 2006 and 2010"
  )
```

# Problem 3

First, I will import the data set.

```{r}
demographic_df =
  read_csv(
    "./data/nhanes_covar.csv",
    skip = 4,
    na = "NA") |>
  janitor::clean_names()

accelerometer_df =
  read_csv("./data/nhanes_accel.csv") |>
  janitor::clean_names()
```